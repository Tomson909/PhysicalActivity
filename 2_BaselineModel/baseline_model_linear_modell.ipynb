{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "As a baseline modell a simple regression modell is mostly a good starting point. A appropriate modell for a classification problem is logistic regression, which I will use in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "The features will be the different activities. The train dataset will be based on the first 7 people in the datset whereas the test dataset will be the last of the 8 different people who gathered data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Mapping: {'Nordic walking': 0, 'ascending stairs': 1, 'cycling': 2, 'descending stairs': 3, 'ironing': 4, 'lying': 5, 'rope jumping': 6, 'running': 7, 'sitting': 8, 'standing': 9, 'transient activities': 10, 'vacuum cleaning': 11, 'walking': 12}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('/home/tomruge/Schreibtisch/UNI/Semester_7/machine_learning_with_tensorflow/archive_physical_activity.csv', engine='pyarrow')\n",
    "\n",
    "# apply undersampling. sample down to size of smallest class\n",
    "df = df.groupby('activityID').apply(lambda x: x.sample(df['activityID'].value_counts().min())).reset_index(drop=True)\n",
    "\n",
    "# Drop all rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Mask for train and test split\n",
    "mask = (df['PeopleId'] == 8)\n",
    "\n",
    "# Use LabelEncoder to automatically assign numerical values to classes\n",
    "label_encoder = LabelEncoder()\n",
    "df['activityID'] = label_encoder.fit_transform(df['activityID'])\n",
    "\n",
    "# Print the mapping of original class labels to numerical labels\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(\"Label Mapping:\", label_mapping)\n",
    "\n",
    "y_train = df['activityID'][~mask]\n",
    "X_train = df.drop(['activityID'], axis=1)[~mask]\n",
    "\n",
    "y_test = df['activityID'][mask]\n",
    "X_test = df.drop(['activityID'], axis=1)[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "Logistic regression:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeopleId_mask: 0\n",
      "(558597, 32)\n",
      "(0, 32)\n",
      "(558597,)\n",
      "(0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 32)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m     33\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[0;32m---> 34\u001b[0m X_test_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(X_test)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Create and train the logistic regression model\u001b[39;00m\n\u001b[1;32m     37\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(multi_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultinomial\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100000\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_data.py:1004\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1001\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1003\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[0;32m-> 1004\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1005\u001b[0m     X,\n\u001b[1;32m   1006\u001b[0m     reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1007\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1008\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1009\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mFLOAT_DTYPES,\n\u001b[1;32m   1010\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1011\u001b[0m )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:969\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 969\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    970\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    971\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    972\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    973\u001b[0m         )\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    976\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 32)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import copy\n",
    "models = []\n",
    "y_tests = []\n",
    "X_tests = []\n",
    "# Use LabelEncoder to automatically assign numerical values to classes\n",
    "label_encoder = LabelEncoder()\n",
    "df['activityID'] = label_encoder.fit_transform(df['activityID'])\n",
    "\n",
    "for i in range(9):\n",
    "    print(\"PeopleId_mask:\", i)\n",
    "    # Mask for train and test split\n",
    "    mask = (df['PeopleId'] == i)\n",
    "    work_df = copy.copy(df)\n",
    "\n",
    "    # Print the mapping of original class labels to numerical labels\n",
    "    label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "    \n",
    "    y_train = work_df['activityID'][~mask]\n",
    "    X_train = work_df.drop(['activityID'], axis=1, inplace = False)[~mask]\n",
    "\n",
    "    y_test = work_df['activityID'][mask]\n",
    "    X_test = work_df.drop(['activityID'], axis=1, inplace=False)[mask]\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    # Standardize the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Create and train the logistic regression model\n",
    "    model = LogisticRegression(multi_class='multinomial', max_iter=100000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    models.append(copy.copy(model))\n",
    "    y_tests.append(copy.copy(y_test))\n",
    "    X_tests.append(copy.copy(X_test_scaled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "My metrics will be: $$ Accuracy = \\frac{Number\\ of\\ Correct\\ Predictions}{Total\\ Number\\ of\\ Predictions}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_PeopleID: 0\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 1\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 2\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 3\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 4\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 5\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 6\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 7\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n",
      "Test_PeopleID: 8\n",
      "Accuracy: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      6599\n",
      "           1       0.29      0.60      0.39      4341\n",
      "           2       0.60      0.93      0.73      6546\n",
      "           3       0.16      0.38      0.22      3948\n",
      "           4       0.00      0.00      0.00      6017\n",
      "           5       1.00      0.94      0.97      5418\n",
      "           6       0.71      0.65      0.68      8806\n",
      "           7       0.46      0.52      0.49      7299\n",
      "           8       0.02      0.00      0.00      5447\n",
      "           9       0.01      0.01      0.01      5675\n",
      "          10       0.15      0.21      0.18      6697\n",
      "          11       0.30      0.38      0.34      5956\n",
      "          12       0.41      0.58      0.48      5679\n",
      "\n",
      "    accuracy                           0.41     78428\n",
      "   macro avg       0.32      0.40      0.34     78428\n",
      "weighted avg       0.33      0.41      0.36     78428\n",
      "\n",
      "Unique values in y_tests: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "Unique values in y_pred_labels_list: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "y_pred_labels_list = []\n",
    "\n",
    "for i in range(9):\n",
    "    print(\"Test_PeopleID:\", i)\n",
    "    \n",
    "    # Make predictions on the test set\n",
    "    y_pred = models[i].predict(X_tests[i])\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_tests[i], y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "    # Display classification report\n",
    "    print(classification_report(y_tests[i], y_pred))\n",
    "    y_pred_labels_list.append(y_pred)\n",
    "\n",
    "    # Check if all entries in y_tests and y_pred_labels_list are the same\n",
    "    print(f\"Unique values in y_tests: {set(y_tests[i])}\")\n",
    "    print(f\"Unique values in y_pred_labels_list: {set(y_pred_labels_list[i])}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -1",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate the confusion matrix\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y_pred_labels_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: -1"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test[-1], y_pred_labels_list[-1])\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=label_mapping.keys(), yticklabels=label_mapping.keys())\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the modell is confused by transient activities, since they are not well defined and have a big deviation within itself. Also activities which can be seen related like sitting and lying got confused very often. But for a first modell not that bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
